{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "339e8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy deals with large arrays and linear algebra\n",
    "import numpy as np\n",
    "# Library for data manipulation and analysis\n",
    "import pandas as pd \n",
    " \n",
    "# Metrics for Evaluation of model Accuracy and F1-score\n",
    "from sklearn.metrics  import f1_score,accuracy_score\n",
    " \n",
    "#Importing the Decision Tree from scikit-learn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For splitting of data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbe4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataframe(account_data_list, dataset_type):\n",
    "    dataframe = pd.DataFrame({})\n",
    "    \n",
    "    if dataset_type == \"automated\":\n",
    "        for account_data in account_data_list:\n",
    "            user_follower_count = account_data[\"userFollowerCount\"]\n",
    "            user_following_count = account_data[\"userFollowingCount\"]\n",
    "            follower_following_ratio = user_follower_count/max(1,user_following_count)\n",
    "            \n",
    "            temp_dataframe = pd.Series({\"user_media_count\":account_data[\"userMediaCount\"],\n",
    "                                        \"user_follower_count\":account_data[\"userFollowerCount\"],\n",
    "                                        \"user_following_count\":account_data[\"userFollowingCount\"],\n",
    "                                        \"user_has_highligh_reels\":account_data[\"userHasHighlighReels\"],\n",
    "                                        \"user_has_external_url\":account_data[\"userHasExternalUrl\"],\n",
    "                                        \"user_tags_count\":account_data[\"userTagsCount\"],\n",
    "                                        \"follower_following_ratio\":follower_following_ratio,\n",
    "                                        \"user_biography_length\":account_data[\"userBiographyLength\"],\n",
    "                                        \"username_length\":account_data[\"usernameLength\"],\n",
    "                                        \"username_digit_count\":account_data[\"usernameDigitCount\"],\n",
    "                                        \"media_comment_numbers\":account_data[\"mediaCommentNumbers\"],\n",
    "                                        \"media_comments_are_disabled\":account_data[\"mediaCommentNumbers\"],\n",
    "                                        \"media_has_location_info\":account_data[\"mediaHasLocationInfo\"],\n",
    "                                        \"media_hashtag_numbers\":account_data[\"mediaHashtagNumbers\"],\n",
    "                                        \"media_like_numbers\":account_data[\"mediaLikeNumbers\"],\n",
    "                                        \"mediaUpload_times\":account_data[\"mediaUploadTimes\"],\n",
    "                                        \"automated_behaviour\":account_data[\"automatedBehaviour\"]\n",
    "                                        })\n",
    "            dataframe = dataframe.append(temp_dataframe, ignore_index=True)\n",
    "            \n",
    "    elif dataset_type == \"fake\":\n",
    "        for account_data in account_data_list:\n",
    "            user_follower_count = account_data[\"userFollowerCount\"]\n",
    "            user_following_count = account_data[\"userFollowingCount\"]\n",
    "            follower_following_ratio = user_follower_count/max(1,user_following_count)\n",
    "            \n",
    "            temp_dataframe = pd.Series({\"user_media_count\":account_data[\"userMediaCount\"],\n",
    "                                      \"user_follower_count\":account_data[\"userFollowerCount\"],\n",
    "                                      \"user_following_count\":account_data[\"userFollowingCount\"],\n",
    "                                      \"user_has_profil_pic\":account_data[\"userHasProfilPic\"],\n",
    "                                      \"user_is_private\":account_data[\"userIsPrivate\"],\n",
    "                                      \"follower_following_ratio\":follower_following_ratio,\n",
    "                                      \"user_biography_length\":account_data[\"userBiographyLength\"],\n",
    "                                      \"username_length\":account_data[\"usernameLength\"],\n",
    "                                      \"username_digit_count\":account_data[\"usernameDigitCount\"],\n",
    "                                      \"is_fake\":account_data[\"isFake\"]\n",
    "                                        })\n",
    "            dataframe = dataframe.append(temp_dataframe, ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "#%% Import automated/nonautomated data\n",
    "    \n",
    "def import_data(dataset_path, dataset_version):\n",
    "    #base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "    #base_path = \"/Users/fca/Documents/GitHub/instafake-dataset\"\n",
    "    dataset_type = re.findall(\"automated|fake\",dataset_version)[0]\n",
    "    if dataset_type == \"automated\":\n",
    "        with open(dataset_path + \"/\" + dataset_version + \"/automatedAccountData.json\") as json_file:\n",
    "            automated_account_data = json.load(json_file)\n",
    "        with open(dataset_path + \"/\" + dataset_version + \"/nonautomatedAccountData.json\") as json_file:\n",
    "            nonautomated_account_data = json.load(json_file)\n",
    "            \n",
    "        automated_account_dataframe = create_dataframe(automated_account_data, dataset_type)\n",
    "        nonautomated_account_dataframe = create_dataframe(nonautomated_account_data, dataset_type)\n",
    "        merged_dataframe = automated_account_dataframe.append(nonautomated_account_dataframe, ignore_index=True)\n",
    "        data = dict({\"dataset_type\":dataset_type,\n",
    "                     \"dataframe\":merged_dataframe})\n",
    "    \n",
    "    elif dataset_type == \"fake\":\n",
    "        with open(dataset_path + \"/\" + dataset_version + \"/fakeAccountData.json\") as json_file:\n",
    "            fake_account_data = json.load(json_file)\n",
    "        with open(dataset_path + \"/\" + dataset_version + \"/realAccountData.json\") as json_file:\n",
    "            real_account_data = json.load(json_file)\n",
    "            \n",
    "        fake_account_dataframe = create_dataframe(fake_account_data, dataset_type)\n",
    "        real_account_dataframe = create_dataframe(real_account_data, dataset_type)\n",
    "        merged_dataframe = fake_account_dataframe.append(real_account_dataframe, ignore_index=True)\n",
    "        data = dict({\"dataset_type\":dataset_type,\n",
    "                     \"dataframe\":merged_dataframe})\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa36a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_json(\"./data/fake/fake-data.json\")\n",
    "real_df = pd.read_json(\"./data/fake/real-data.json\")\n",
    "df = pd.concat([fake_df,real_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08d9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.isFake\n",
    "X = df.drop([\"isFake\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad2c1274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userFollowerCount</th>\n",
       "      <th>userFollowingCount</th>\n",
       "      <th>userBiographyLength</th>\n",
       "      <th>userMediaCount</th>\n",
       "      <th>userHasProfilPic</th>\n",
       "      <th>userIsPrivate</th>\n",
       "      <th>usernameDigitCount</th>\n",
       "      <th>usernameLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>369.133779</td>\n",
       "      <td>647.672241</td>\n",
       "      <td>20.846154</td>\n",
       "      <td>57.702341</td>\n",
       "      <td>0.926421</td>\n",
       "      <td>0.682274</td>\n",
       "      <td>0.448161</td>\n",
       "      <td>11.070234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>344.570293</td>\n",
       "      <td>828.622573</td>\n",
       "      <td>31.591931</td>\n",
       "      <td>110.422078</td>\n",
       "      <td>0.261522</td>\n",
       "      <td>0.466373</td>\n",
       "      <td>1.117203</td>\n",
       "      <td>2.837622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>154.500000</td>\n",
       "      <td>256.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>319.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>471.500000</td>\n",
       "      <td>690.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3140.000000</td>\n",
       "      <td>7493.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userFollowerCount  userFollowingCount  userBiographyLength  \\\n",
       "count         299.000000          299.000000           299.000000   \n",
       "mean          369.133779          647.672241            20.846154   \n",
       "std           344.570293          828.622573            31.591931   \n",
       "min             0.000000            0.000000             0.000000   \n",
       "25%           154.500000          256.500000             0.000000   \n",
       "50%           319.000000          454.000000             3.000000   \n",
       "75%           471.500000          690.500000            32.000000   \n",
       "max          3140.000000         7493.000000           150.000000   \n",
       "\n",
       "       userMediaCount  userHasProfilPic  userIsPrivate  usernameDigitCount  \\\n",
       "count      299.000000        299.000000     299.000000          299.000000   \n",
       "mean        57.702341          0.926421       0.682274            0.448161   \n",
       "std        110.422078          0.261522       0.466373            1.117203   \n",
       "min          0.000000          0.000000       0.000000            0.000000   \n",
       "25%          3.000000          1.000000       0.000000            0.000000   \n",
       "50%         20.000000          1.000000       1.000000            0.000000   \n",
       "75%         61.500000          1.000000       1.000000            0.000000   \n",
       "max        875.000000          1.000000       1.000000            7.000000   \n",
       "\n",
       "       usernameLength  \n",
       "count      299.000000  \n",
       "mean        11.070234  \n",
       "std          2.837622  \n",
       "min          5.000000  \n",
       "25%          9.000000  \n",
       "50%         11.000000  \n",
       "75%         13.000000  \n",
       "max         21.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b306992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9565217391304348\n",
      "0.853932584269663\n"
     ]
    }
   ],
   "source": [
    "# Training the model is as simple as this\n",
    "# Use the function imported above and apply fit() on it\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train,y_train)\n",
    "# We use the predict() on the model to predict the output\n",
    "pred=DT.predict(X_test)\n",
    " \n",
    "# for classification we use accuracy and F1 score\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(f1_score(y_test,pred))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc15865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046822742474916385\n",
      "0.046822742474916385\n"
     ]
    }
   ],
   "source": [
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "print(mean_absolute_error(y_test,pred))\n",
    "print(mean_absolute_error(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a6af73",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/76zf8tr108q3ywb78ksn7wtw0000gn/T/ipykernel_16865/3961863225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "pred = SVC().predict(X_test)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d49708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_model(class_, X_train,X_test,y_train,y_test):\n",
    "    c = class_()\n",
    "    c.fit(X_train,y_train)\n",
    "    pred = c.predict(X_test)\n",
    "    # for classification we use accuracy and F1 score\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test,pred)}, F1 score: {f1_score(y_test,pred)}\")\n",
    "    filename = f'{class_.__name__}_finalized_model.sav'\n",
    "    pickle.dump(c, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed62445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Model DecisionTreeClassifier ----\n",
      "Accuracy score: 0.9565217391304348, F1 score: 0.853932584269663\n",
      "---- Model LogisticRegression ----\n",
      "Accuracy score: 0.939799331103679, F1 score: 0.775\n",
      "---- Model SVC ----\n",
      "Accuracy score: 0.9230769230769231, F1 score: 0.6933333333333335\n",
      "---- Model GaussianNB ----\n",
      "Accuracy score: 0.9096989966555183, F1 score: 0.7032967032967034\n",
      "---- Model MultinomialNB ----\n",
      "Accuracy score: 0.9464882943143813, F1 score: 0.8095238095238095\n",
      "---- Model SGDClassifier ----\n",
      "Accuracy score: 0.939799331103679, F1 score: 0.763157894736842\n",
      "---- Model GradientBoostingClassifier ----\n",
      "Accuracy score: 0.9565217391304348, F1 score: 0.8470588235294116\n",
      "---- Model RandomForestClassifier ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9632107023411371, F1 score: 0.8735632183908046\n"
     ]
    }
   ],
   "source": [
    "classifiers = [DecisionTreeClassifier,LogisticRegression,SVC,GaussianNB,MultinomialNB,SGDClassifier,GradientBoostingClassifier,RandomForestClassifier]\n",
    "for classifier in classifiers:\n",
    "    print(f\"---- Model {classifier.__name__} ----\")\n",
    "    evaluate_using_model(classifier, X_train,X_test,y_train,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f50ddd09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/76zf8tr108q3ywb78ksn7wtw0000gn/T/ipykernel_16865/2882475047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1cf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
